# ğŸ«€ Sistema de Machine Learning para PredicciÃ³n de Salud Cardiovascular

## ğŸ“‹ InformaciÃ³n del Proyecto

**Estudiante:** Celadita  
**Grupo:** A-C (Problema de Salud)  
**Tipo de Problema:** RegresiÃ³n Supervisada  
**Variable Objetivo:** BMI (Ãndice de Masa Corporal)  
**Dataset:** Heart Disease Health Indicators (Kaggle CDC)

---

## ğŸ¯ Objetivo

Desarrollar un sistema completo de Machine Learning Supervisado que compare el desempeÃ±o de 4 modelos de regresiÃ³n (2 de caja blanca y 2 de caja negra) para predecir valores de BMI basÃ¡ndose en indicadores de salud cardiovascular.

---

## ğŸ“¦ Estructura del Proyecto

```
proyecto-ml-salud/
â”‚
â”œâ”€â”€ README.md                                    âœ“ DocumentaciÃ³n principal
â”œâ”€â”€ requirements.txt                             âœ“ Dependencias
â”œâ”€â”€ main.py                                      âœ“ Pipeline completo
â”œâ”€â”€ app_streamlit.py                             âœ“ Interfaz GUI
â”œâ”€â”€ utils.py                                     âœ“ Utilidades
â”‚
â”œâ”€â”€ heart_disease_health_indicators.csv          âœ“ Dataset
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ informe_tecnico.md                       âœ“ Informe detallado
â”‚   â””â”€â”€ presentacion.pdf                         â—‹ Opcional
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ metricas_comparacion.png                 âœ“ GrÃ¡fico comparativo
â”‚   â”œâ”€â”€ predicciones_vs_reales.png               âœ“ Scatter plot
â”‚   â”œâ”€â”€ distribucion_errores.png                 âœ“ Histograma
â”‚   â”œâ”€â”€ importancia_caracteristicas.png          âœ“ Feature importance
â”‚   â””â”€â”€ resultados_modelos.csv                   âœ“ Tabla de resultados
â”‚
â”œâ”€â”€ models/                                      â—‹ Modelos guardados (opcional)
â”‚   â”œâ”€â”€ random_forest.joblib
â”‚   â””â”€â”€ scaler.joblib
â”‚
â””â”€â”€ screenshots/                                 â—‹ Capturas GUI (opcional)
    â”œâ”€â”€ gui_dataset.png
    â”œâ”€â”€ gui_training.png
    â””â”€â”€ gui_results.png
```

Leyenda:

âœ“ = Obligatorio
â—‹ = Opcional/Recomendado

---

## ğŸ› ï¸ Requisitos e InstalaciÃ³n

### Requisitos del Sistema

- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- 4GB RAM mÃ­nimo (recomendado 8GB)
- Espacio en disco: 500MB

### InstalaciÃ³n de Dependencias

1. **Clonar o descargar el proyecto:**

```bash
cd proyecto-ml-salud
```

2. **Crear entorno virtual (recomendado):**

```bash
# Windows
py -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

3. **Instalar dependencias:**

```bash
pip install -r requirements.txt
```

### Contenido de `requirements.txt`:

```txt
pandas==2.0.3
numpy==1.24.3
matplotlib==3.7.2
seaborn==0.12.2
scikit-learn==1.3.0
streamlit==1.25.0
```

---

## ğŸ“Š ObtenciÃ³n del Dataset

1. Ir a Kaggle: https://www.kaggle.com/datasets/alexteboul/heart-disease-health-indicators-dataset

2. Descargar el archivo `heart_disease_health_indicators.csv`

3. Colocar el archivo en la carpeta raÃ­z del proyecto

**InformaciÃ³n del Dataset:**
- **Registros:** 253,680
- **Variables:** 22
- **Fuente:** CDC (Centers for Disease Control and Prevention)
- **Variable Objetivo:** BMI (numÃ©rica continua)

---

## ğŸš€ EjecuciÃ³n del Sistema

### OpciÃ³n 1: Script de LÃ­nea de Comandos

Ejecutar el pipeline completo:

```bash
python main.py
```

**Salidas generadas:**
- MÃ©tricas en consola
- GrÃ¡ficos guardados en carpeta `outputs/`
- Archivo CSV con resultados: `resultados_modelos.csv`

### OpciÃ³n 2: Interfaz GrÃ¡fica (Streamlit)

Iniciar la aplicaciÃ³n web interactiva:

```bash
streamlit run app_streamlit.py
```

**Funcionalidades de la GUI:**
- âœ… Carga interactiva del dataset
- âœ… VisualizaciÃ³n de datos exploratoria
- âœ… ConfiguraciÃ³n de parÃ¡metros
- âœ… Entrenamiento con barra de progreso
- âœ… ComparaciÃ³n visual de modelos
- âœ… PredicciÃ³n individual en tiempo real

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en `http://localhost:8501`

---

## ğŸ§  Modelos Implementados

### Modelos de Caja Blanca (Interpretables)

1. **RegresiÃ³n Lineal**
   - Algoritmo: OLS (Ordinary Least Squares)
   - Ventaja: InterpretaciÃ³n directa de coeficientes
   - LimitaciÃ³n: Asume relaciÃ³n lineal

2. **Ãrbol de DecisiÃ³n Regressor**
   - Algoritmo: CART (Classification and Regression Trees)
   - Ventaja: InterpretaciÃ³n visual clara
   - LimitaciÃ³n: Propenso a sobreajuste

### Modelos de Caja Negra (Mayor Complejidad)

3. **Random Forest Regressor**
   - Algoritmo: Ensamble de Ã¡rboles
   - ParÃ¡metros: 100 estimadores (default)
   - Ventaja: Robusto y preciso

4. **Support Vector Regressor (SVR)**
   - Kernel: RBF (Radial Basis Function)
   - Ventaja: Efectivo en alta dimensionalidad
   - LimitaciÃ³n: Alto costo computacional

---

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

El sistema calcula las siguientes mÃ©tricas para cada modelo:

| MÃ©trica | DescripciÃ³n | InterpretaciÃ³n |
|---------|-------------|----------------|
| **MAE** | Mean Absolute Error | Error promedio absoluto (menor es mejor) |
| **MSE** | Mean Squared Error | Error cuadrÃ¡tico medio (penaliza errores grandes) |
| **RMSE** | Root Mean Squared Error | RaÃ­z del MSE, en las mismas unidades del target |
| **RÂ²** | Coeficiente de DeterminaciÃ³n | ProporciÃ³n de varianza explicada (0 a 1, mayor es mejor) |

---

## ğŸ”¬ MetodologÃ­a

### 1. Preprocesamiento

```python
# Pasos aplicados:
1. EliminaciÃ³n de duplicados
2. Tratamiento de outliers (mÃ©todo IQR)
3. NormalizaciÃ³n con StandardScaler
4. DivisiÃ³n train/test (80/20)
```

### 2. ValidaciÃ³n

- **MÃ©todo:** K-Fold Cross Validation
- **K:** 5 pliegues
- **MÃ©trica:** RÂ² Score
- **PropÃ³sito:** Evaluar estabilidad del modelo

### 3. Entrenamiento

- **HiperparÃ¡metros:** ConfiguraciÃ³n por defecto
- **Semilla aleatoria:** 42 (reproducibilidad)
- **ParalelizaciÃ³n:** n_jobs=-1 (usa todos los cores)

---

## ğŸ“Š Resultados Esperados

### Tabla Comparativa (Ejemplo)

| Modelo | Tipo | MAE | RMSE | RÂ² |
|--------|------|-----|------|----|
| RegresiÃ³n Lineal | Caja Blanca | 4.91 | 6.24 | 0.3087 |
| Ãrbol de DecisiÃ³n | Caja Blanca | 3.56 | 5.30 | 0.4998 |
| **Random Forest** | **Caja Negra** | **3.02** | **4.38** | **0.6583** |
| SVR | Caja Negra | 4.61 | 6.00 | 0.3602 |

### InterpretaciÃ³n

ğŸ† **Mejor Modelo:** Random Forest
- **RÂ² = 0.6583** â†’ Explica 65.83% de la varianza del BMI
- **RMSE = 4.38** â†’ Error promedio de ~4.38 puntos de BMI
- **ConclusiÃ³n:** Balance Ã³ptimo entre precisiÃ³n y generalizaciÃ³n

---

## ğŸ¯ Uso de la Interfaz GUI

### Flujo de Trabajo

1. **PestaÃ±a "Dataset"**
   - Cargar el archivo CSV
   - Explorar estadÃ­sticas bÃ¡sicas
   - Visualizar distribuciÃ³n de BMI

2. **PestaÃ±a "Preprocesamiento"**
   - Revisar pasos de limpieza
   - Ejecutar preprocesamiento
   - Confirmar divisiÃ³n de datos

3. **PestaÃ±a "Entrenamiento"**
   - Revisar configuraciÃ³n de modelos
   - Iniciar entrenamiento (con barra de progreso)
   - Ver resumen de validaciÃ³n cruzada

4. **PestaÃ±a "Resultados"**
   - Comparar mÃ©tricas en tabla
   - Visualizar grÃ¡ficos comparativos
   - Analizar predicciones vs valores reales
   - Ver importancia de caracterÃ­sticas

5. **PestaÃ±a "PredicciÃ³n"**
   - Ingresar valores de caracterÃ­sticas
   - Obtener predicciÃ³n de BMI
   - Ver interpretaciÃ³n clÃ­nica

---

## ğŸ–¼ï¸ Visualizaciones Generadas

### 1. ComparaciÃ³n de MÃ©tricas
- GrÃ¡ficos de barras para MAE, MSE, RMSE, RÂ²
- DiferenciaciÃ³n por colores (caja blanca vs caja negra)

### 2. Predicciones vs Valores Reales
- Scatter plot con lÃ­nea de predicciÃ³n perfecta
- Permite identificar patrones de error

### 3. DistribuciÃ³n de Errores
- Histograma de errores de predicciÃ³n
- Verifica normalidad de residuos

### 4. Importancia de CaracterÃ­sticas
- Top 15 features mÃ¡s importantes (Random Forest)
- Ãštil para interpretaciÃ³n del modelo

---

## ğŸ” InterpretaciÃ³n ClÃ­nica del BMI

La interfaz proporciona interpretaciÃ³n automÃ¡tica segÃºn rangos OMS:

| Rango BMI | CategorÃ­a | RecomendaciÃ³n |
|-----------|-----------|---------------|
| < 18.5 | Bajo peso | EvaluaciÃ³n nutricional |
| 18.5 - 24.9 | Peso normal | Mantener hÃ¡bitos saludables |
| 25.0 - 29.9 | Sobrepeso | Plan de manejo de peso |
| â‰¥ 30.0 | Obesidad | EvaluaciÃ³n mÃ©dica integral |

---

## ğŸ› SoluciÃ³n de Problemas

### Error: "FileNotFoundError: heart_disease_health_indicators.csv"

**SoluciÃ³n:** Descargar el dataset de Kaggle y colocarlo en la carpeta raÃ­z.

### Error: "ModuleNotFoundError: No module named 'sklearn'"

**SoluciÃ³n:** 
```bash
pip install scikit-learn
```

### Error: "Streamlit no abre en el navegador"

**SoluciÃ³n:**
```bash
# Abrir manualmente en:
http://localhost:8501
```

### Advertencia: "MemoryError"

**SoluciÃ³n:** Reducir el tamaÃ±o del dataset o aumentar RAM disponible.

### Entrenamiento muy lento (SVR)

**Causa:** SVR es computacionalmente costoso con datasets grandes.  
**SoluciÃ³n:** Esperar o reducir tamaÃ±o del dataset de entrenamiento.

---

## ğŸ“ Variables del Dataset

### Variables Independientes (Features)

| Variable | DescripciÃ³n | Tipo |
|----------|-------------|------|
| HighBP | PresiÃ³n arterial alta | Binaria (0/1) |
| HighChol | Colesterol alto | Binaria (0/1) |
| CholCheck | Chequeo de colesterol en Ãºltimos 5 aÃ±os | Binaria (0/1) |
| Smoker | Fumador (mÃ¡s de 100 cigarrillos) | Binaria (0/1) |
| Stroke | Historial de derrame cerebral | Binaria (0/1) |
| Diabetes | Diabetes (0=no, 1=pre-diabetes, 2=diabetes) | CategÃ³rica |
| PhysActivity | Actividad fÃ­sica en Ãºltimos 30 dÃ­as | Binaria (0/1) |
| Fruits | Consume frutas 1+ vez al dÃ­a | Binaria (0/1) |
| Veggies | Consume vegetales 1+ vez al dÃ­a | Binaria (0/1) |
| HvyAlcoholConsump | Consumo excesivo de alcohol | Binaria (0/1) |
| AnyHealthcare | Tiene seguro mÃ©dico | Binaria (0/1) |
| NoDocbcCost | No visitÃ³ mÃ©dico por costo | Binaria (0/1) |
| GenHlth | Salud general (1=excelente, 5=pobre) | Ordinal |
| MentHlth | DÃ­as de mala salud mental (Ãºltimos 30) | NumÃ©rica (0-30) |
| PhysHlth | DÃ­as de mala salud fÃ­sica (Ãºltimos 30) | NumÃ©rica (0-30) |
| DiffWalk | Dificultad para caminar/subir escaleras | Binaria (0/1) |
| Sex | Sexo (0=femenino, 1=masculino) | Binaria (0/1) |
| Age | CategorÃ­a de edad (1-13) | Ordinal |
| Education | Nivel educativo (1-6) | Ordinal |
| Income | CategorÃ­a de ingresos (1-8) | Ordinal |
| HeartDiseaseorAttack | Historial de enfermedad cardÃ­aca | Binaria (0/1) |

### Variable Dependiente (Target)

| Variable | DescripciÃ³n | Tipo | Rango |
|----------|-------------|------|-------|
| **BMI** | Ãndice de Masa Corporal (peso/alturaÂ²) | NumÃ©rica continua | 12-98 kg/mÂ² |

---

## ğŸ“š Referencias y Recursos

### LibrerÃ­as Utilizadas

- **Pandas:** ManipulaciÃ³n de datos tabulares
- **NumPy:** Operaciones numÃ©ricas y matrices
- **Scikit-learn:** Algoritmos de ML y preprocessing
- **Matplotlib/Seaborn:** VisualizaciÃ³n de datos
- **Streamlit:** Framework para aplicaciones web

### DocumentaciÃ³n

- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Dataset en Kaggle](https://www.kaggle.com/datasets/alexteboul/heart-disease-health-indicators-dataset)

### Papers Relacionados

- Breiman, L. (2001). "Random Forests". Machine Learning.
- Vapnik, V. (1995). "The Nature of Statistical Learning Theory".

---

## ğŸ“ Criterios de EvaluaciÃ³n AcadÃ©mica

### Cumplimiento de Requisitos

âœ… Dataset de salud de Kaggle (no imÃ¡genes)  
âœ… Variable objetivo numÃ©rica continua (BMI)  
âœ… Preprocesamiento completo (limpieza, normalizaciÃ³n)  
âœ… DivisiÃ³n 80/20 train/test  
âœ… ValidaciÃ³n cruzada K=5  
âœ… 2 modelos caja blanca + 2 caja negra  
âœ… HiperparÃ¡metros por defecto  
âœ… MÃ©tricas: MAE, MSE, RMSE, RÂ²  
âœ… Tabla comparativa de modelos  
âœ… Interfaz GUI funcional (Streamlit)  
âœ… Visualizaciones de resultados  
âœ… CÃ³digo comentado y documentado  

---

## ğŸ’¡ Conclusiones del Proyecto

### Hallazgos Principales

1. **Superioridad de ensambles:** Random Forest superÃ³ significativamente a modelos individuales.

2. **Limitaciones de linealidad:** La RegresiÃ³n Lineal (RÂ²=0.31) confirma que las relaciones entre variables de salud son predominantemente no lineales.

3. **Costo-beneficio:** SVR no justifica su alto costo computacional frente a Random Forest.

4. **Interpretabilidad vs PrecisiÃ³n:** Existe un trade-off claro entre la interpretabilidad de modelos simples y la precisiÃ³n de modelos complejos.

### AplicaciÃ³n PrÃ¡ctica

- El sistema puede integrarse en aplicaciones de screening de salud poblacional
- La predicciÃ³n de BMI permite identificar individuos en riesgo cardiovascular
- Las caracterÃ­sticas mÃ¡s importantes pueden guiar campaÃ±as de prevenciÃ³n

### Trabajo Futuro

1. **OptimizaciÃ³n de hiperparÃ¡metros** mediante Grid Search o Bayesian Optimization
2. **Feature engineering** para crear variables derivadas mÃ¡s informativas
3. **Modelos avanzados** como XGBoost, LightGBM o Deep Learning
4. **Interpretabilidad** con SHAP values para explicar predicciones individuales
5. **Despliegue en producciÃ³n** con Docker y APIs REST

---

## ğŸ‘¤ Autor

**Estudiante:** Celadita  
**Curso:** Machine Learning Supervisado  
**AÃ±o:** 2025  
**InstituciÃ³n:** [Universidad]

---

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico y educativo.

---

## ğŸ™ Agradecimientos

- Kaggle y CDC por proporcionar el dataset
- Comunidad de Scikit-learn por las herramientas de ML
- Streamlit por facilitar la creaciÃ³n de interfaces web

---

## ğŸ“ Soporte

Para preguntas o problemas:
1. Revisar la secciÃ³n "SoluciÃ³n de Problemas"
2. Verificar la documentaciÃ³n de las librerÃ­as
3. Consultar los foros de Kaggle y Stack Overflow

---

**Ãšltima actualizaciÃ³n:** Octubre 2025  
**VersiÃ³n:** 1.0.0